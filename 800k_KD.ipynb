{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VtKwjMgeU1nk"
   },
   "source": [
    "## Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/unmounted/NeuralCompression/neuralcompression/__init__.py:21: UserWarning: Could not retrieve neuralcompression version!\n",
      "  warnings.warn(\"Could not retrieve neuralcompression version!\")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from student_v1 import StudentEncoderBase_V2\n",
    "from lib.loss import get_loss_functions\n",
    "import torch.optim as optim\n",
    "from lib.data_handlers.CLIC_dataset import build_trainloader\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import NeuralCompression.neuralcompression.functional as ncF\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y5p39IDbMUt9",
    "outputId": "4808ea4e-6dc2-4b14-fc70-b261ad39a493"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/facebookresearch/NeuralCompression/zipball/main\" to /root/.cache/torch/hub/main.zip\n",
      "/root/.cache/torch/hub/facebookresearch_NeuralCompression_main/neuralcompression/__init__.py:21: UserWarning: Could not retrieve neuralcompression version!\n",
      "  warnings.warn(\"Could not retrieve neuralcompression version!\")\n"
     ]
    }
   ],
   "source": [
    "# Import GAN Model\n",
    "model = torch.hub.load(\"facebookresearch/NeuralCompression\", \"msillm_quality_3\", force_reload=True)\n",
    "model = model.eval()\n",
    "model.update()\n",
    "model.update_tensor_devices(\"compress\")\n",
    "\n",
    "# Freeze Model\n",
    "for p in model.parameters():\n",
    "    p.requires_grad = False\n",
    "\n",
    "# Setup Teacher/Student\n",
    "teacher = model.encoder\n",
    "student = StudentEncoderBase_V2()\n",
    "# student.load_state_dict(torch.load(\"/workspace/unmounted/models/model_35ep.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "msssim_loss, vgg_perceptual, distillation_loss = get_loss_functions()\n",
    "vgg_perceptual = vgg_perceptual.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "jbZBzzm1MuMw"
   },
   "outputs": [],
   "source": [
    "## Grid Search Params\n",
    "alpha_hint1 = 0.01\n",
    "alpha_hint2 = 0.035\n",
    "alpha_hint3 = 0.035\n",
    "alpha_hint4 = 0.035\n",
    "alpha_hint4 = 0.035\n",
    "beta_latent = 0.7\n",
    "gamma_msssim = 0.01\n",
    "gamma_perc = 0.001\n",
    "learning_rate = 0.0085"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fHOkY-3_M1dO"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "8RZODIBUNe45"
   },
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(student.parameters(), lr=learning_rate)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=30, eta_min=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LossLogger:\n",
    "    def __init__(self):\n",
    "        self.loss_names = [\n",
    "            'avg_hint1_loss', 'avg_hint2_loss', 'avg_hint3_loss', 'avg_hint4_loss', 'avg_hint5_loss',\n",
    "            'avg_latent_loss', 'avg_ssim_loss', 'avg_perc_loss', 'epoch_loss'\n",
    "        ]\n",
    "        self.losses = {name: [] for name in self.loss_names}\n",
    "\n",
    "    def log(self, loss_tuple):\n",
    "        assert len(loss_tuple) == len(self.loss_names), \"Mismatch in number of losses\"\n",
    "        for name, value in zip(self.loss_names, loss_tuple):\n",
    "            self.losses[name].append(value)\n",
    "\n",
    "    def plot(self):\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        for name, values in self.losses.items():\n",
    "            plt.plot(values, label=name)\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.title(\"Losses over Epochs\")\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    def save(self, path):\n",
    "        torch.save(self.losses, path)\n",
    "\n",
    "    def load(self, path):\n",
    "        self.losses = torch.load(path)\n",
    "        assert all(name in self.losses for name in self.loss_names), \"Loaded file missing some loss keys\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = LossLogger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TqQImR73NiWZ"
   },
   "outputs": [],
   "source": [
    "model.decoder.to(device)\n",
    "student.to(device)\n",
    "vgg_perceptual = vgg_perceptual.to(device)\n",
    "\n",
    "def train_epoch(dataloader, epoch=None):\n",
    "    student.train()\n",
    "    running_loss = 0.0\n",
    "    total_hint1_loss = 0.0\n",
    "    total_hint2_loss = 0.0\n",
    "    total_hint3_loss = 0.0\n",
    "    total_hint4_loss = 0.0\n",
    "    total_hint5_loss = 0.0\n",
    "    total_latent_loss = 0.0\n",
    "    total_ssim_loss = 0.0\n",
    "    total_perc_loss = 0.0\n",
    "\n",
    "\n",
    "    student.to(device)\n",
    "    # Add TQDM loader\n",
    "    loop = tqdm(enumerate(dataloader), total=len(dataloader), desc=f\"Epoch {epoch if epoch is not None else ''}\")\n",
    "\n",
    "    for i, batch in loop:\n",
    "        \n",
    "        x = batch[\"images\"]\n",
    "        x = x.to(device)\n",
    "        # Padding Correction        \n",
    "        x, (_, _) = ncF.pad_image_to_factor(x, model._factor)\n",
    "         \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        y = student.block1(x)\n",
    "        \n",
    "        y = y.to(device)\n",
    "        z1 = batch['layer1'].to(device)\n",
    "        z2 = batch['layer2'].to(device)\n",
    "        z3 = batch['layer3'].to(device)\n",
    "        z4 = batch['layer4'].to(device)\n",
    "        z5 = batch['layer5'].to(device)\n",
    "        z6 = batch['layer6'].to(device)\n",
    "        \n",
    "        \n",
    "        hint1_loss = distillation_loss(y, z1)\n",
    "\n",
    "        y = student.block2(y)\n",
    "        hint2_loss = distillation_loss(y, z2)\n",
    "        \n",
    "        y = student.block3(y)\n",
    "        hint3_loss = distillation_loss(y, z3)\n",
    "        \n",
    "        y = student.block4(y)\n",
    "        hint4_loss = distillation_loss(y, z4)\n",
    "        \n",
    "        y = student.block5(y)\n",
    "        hint5_loss = distillation_loss(y, z5)\n",
    "        \n",
    "        y = student.block6(y)\n",
    "        latent_loss = distillation_loss(y, z6)\n",
    "\n",
    "        \n",
    "        x_recon = model.decoder(y)\n",
    "            \n",
    "        perc_loss = vgg_perceptual(x, x_recon)\n",
    "        ssim_loss = msssim_loss(x, x_recon)\n",
    "\n",
    "        # Cumulative Loss\n",
    "        loss = (1.0 * hint1_loss\n",
    "                + 1.0 * hint2_loss\n",
    "                + 1.0 * hint3_loss\n",
    "                + 1.0 * hint4_loss\n",
    "                + 1.0 * hint5_loss\n",
    "                + 1.0 * latent_loss\n",
    "                + gamma_msssim * ssim_loss\n",
    "                + gamma_perc * perc_loss)\n",
    "\n",
    "        # Backprop and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Accumulate loss values\n",
    "        running_loss += loss.item() * x.size(0)\n",
    "        total_hint1_loss += hint1_loss.item() * x.size(0)\n",
    "        total_hint2_loss += hint2_loss.item() * x.size(0)\n",
    "        total_hint3_loss += hint3_loss.item() * x.size(0)\n",
    "        total_hint4_loss += hint4_loss.item() * x.size(0)\n",
    "        total_hint5_loss += hint5_loss.item() * x.size(0)\n",
    "        \n",
    "        total_latent_loss += latent_loss.item() * x.size(0)\n",
    "        total_ssim_loss += ssim_loss.item() * x.size(0)\n",
    "        total_perc_loss += perc_loss.item() * x.size(0)\n",
    "\n",
    "    # Average losses\n",
    "    dataset_size = len(dataloader.dataset)\n",
    "    epoch_loss = running_loss / dataset_size\n",
    "    \n",
    "    avg_hint1_loss = total_hint1_loss / dataset_size\n",
    "    avg_hint2_loss = total_hint2_loss / dataset_size\n",
    "    avg_hint3_loss = total_hint3_loss / dataset_size\n",
    "    avg_hint4_loss = total_hint4_loss / dataset_size\n",
    "    avg_hint5_loss = total_hint5_loss / dataset_size\n",
    "    \n",
    "    avg_latent_loss = total_latent_loss / dataset_size\n",
    "    avg_ssim_loss = total_ssim_loss / dataset_size\n",
    "    avg_perc_loss = total_perc_loss / dataset_size\n",
    "    \n",
    "    \n",
    "    print(\"Component-Wise Loss\")\n",
    "    print(\"Hint 1: \", avg_hint1_loss)\n",
    "    print(\"Hint 2: \", avg_hint2_loss)\n",
    "    print(\"Hint 3: \", avg_hint3_loss)\n",
    "    print(\"Hint 4: \", avg_hint4_loss)\n",
    "    print(\"Hint 5: \", avg_hint5_loss)\n",
    "    print(\"Latent Loss: \", avg_latent_loss)\n",
    "    print(\"SSIM Loss: \", avg_ssim_loss)\n",
    "    print(\"VGG Loss: \", avg_perc_loss)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Plot reconstructed image after the epoch\n",
    "    x_vis = x[0].detach().cpu().permute(1, 2, 0)\n",
    "    x_recon_vis = x_recon[0].detach().cpu().permute(1, 2, 0)\n",
    "\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "    axs[0].imshow(x_vis)\n",
    "    axs[0].set_title(\"Original Image\")\n",
    "    axs[0].axis('off')\n",
    "\n",
    "    axs[1].imshow(x_recon_vis)\n",
    "    axs[1].set_title(\"Reconstructed Image\")\n",
    "    axs[1].axis('off')\n",
    "\n",
    "    plt.suptitle(f\"Reconstruction at Epoch {epoch}\")\n",
    "    plt.show()\n",
    "\n",
    "    return avg_hint1_loss, avg_hint2_loss, avg_hint3_loss, avg_hint4_loss, avg_hint5_loss, avg_latent_loss, avg_ssim_loss, avg_perc_loss, epoch_loss \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2Cq3oPTZN94v"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "naHC0lpgPU8K",
    "outputId": "ff275beb-f730-4bab-fbfa-7debc937ac17"
   },
   "outputs": [],
   "source": [
    "from lib.data_handlers.CLIC_dataset import build_activation_dataloader\n",
    "loader = build_activation_dataloader(dir=\"/workspace/unmounted/CLIC_activations/ILLM_Q3_torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  28%|██▊       | 44/157 [00:46<01:59,  1.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3548, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_1915/2609219322.py\", line 6, in <module>\n",
      "    train_loss = train_epoch(loader, epoch=epoch)\n",
      "  File \"/tmp/ipykernel_1915/3797491259.py\", line 22, in train_epoch\n",
      "    for i, batch in loop:\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/tqdm/std.py\", line 1181, in __iter__\n",
      "    for obj in iterable:\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 630, in __next__\n",
      "    data = self._next_data()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 674, in _next_data\n",
      "    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\", line 51, in fetch\n",
      "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\", line 51, in <listcomp>\n",
      "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
      "  File \"/workspace/unmounted/CLIC_dataset.py\", line 106, in __getitem__\n",
      "    data = torch.load(self.files[idx])\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 1014, in load\n",
      "    return _load(opened_zipfile,\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 1422, in _load\n",
      "    result = unpickler.load()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 1392, in persistent_load\n",
      "    typed_storage = load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 1357, in load_tensor\n",
      "    storage = zip_file.get_storage_from_record(name, numel, torch.UntypedStorage)._typed_storage()._untyped_storage\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2142, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1435, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1326, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1173, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1063, in format_exception_as_a_whole\n",
      "    self.get_records(etb, number_of_lines_of_context, tb_offset) if etb else []\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1160, in get_records\n",
      "    res = list(stack_data.FrameInfo.stack_data(etb, options=options))[tb_offset:]\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/stack_data/core.py\", line 597, in stack_data\n",
      "    yield from collapse_repeated(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/stack_data/utils.py\", line 83, in collapse_repeated\n",
      "    yield from map(mapper, original_group)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/stack_data/core.py\", line 587, in mapper\n",
      "    return cls(f, options)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/stack_data/core.py\", line 551, in __init__\n",
      "    self.executing = Source.executing(frame_or_tb)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/executing/executing.py\", line 264, in executing\n",
      "    source = cls.for_frame(frame)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/executing/executing.py\", line 183, in for_frame\n",
      "    return cls.for_filename(frame.f_code.co_filename, frame.f_globals or {}, use_cache)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/executing/executing.py\", line 212, in for_filename\n",
      "    return cls._for_filename_and_lines(filename, tuple(lines))\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/executing/executing.py\", line 223, in _for_filename_and_lines\n",
      "    result = source_cache[(filename, lines)] = cls(filename, lines)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/executing/executing.py\", line 171, in __init__\n",
      "    self._nodes_by_line[lineno].append(node)\n",
      "SystemError: attempting to create PyCFunction with class but no METH_METHOD flag\n"
     ]
    }
   ],
   "source": [
    "# Example training loop\n",
    "num_epochs = 200\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    #torch.cuda.empty_cache()  # Frees cached memory (not allocated memory)\n",
    "    train_loss = train_epoch(loader, epoch=epoch)\n",
    "    logger.log(train_loss)\n",
    "    scheduler.step()\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {train_loss[0]:.4f}\")\n",
    "    #torch.cuda.synchronize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(student.state_dict(), \"/workspace/unmounted/models/model800k_200ep_grid.pth\")\n",
    "logger.save(\"/workspace/unmounted/runs/model800k_200ep_grid_loss.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iUIsYJiebodq"
   },
   "source": [
    "## Quantization Aware Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N9MPYK43bqqn"
   },
   "outputs": [],
   "source": [
    "# Custom QAT configuration (adjust as needed)\n",
    "qat_config = QConfig(\n",
    "    activation=default_fake_quant.with_args(observer=torch.ao.quantization.MovingAverageMinMaxObserver,\n",
    "                                           quant_min=0,\n",
    "                                           quant_max=255,\n",
    "                                           dtype=torch.quint8),\n",
    "    weight=default_weight_fake_quant.with_args(observer=torch.ao.quantization.MinMaxObserver,\n",
    "                                              quant_min=-128,\n",
    "                                              quant_max=127,\n",
    "                                              dtype=torch.qint8)\n",
    ")\n",
    "\n",
    "# Apply configuration to student model\n",
    "student.qconfig = qat_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7x7eIT2-b4kk"
   },
   "outputs": [],
   "source": [
    "# Prepare model for QAT (inserts fake quantization modules)\n",
    "student_prepared = prepare_qat(student, inplace=False).to(device)\n",
    "student = student_prepared\n",
    "# If using FX Graph Mode (recommended for complex models):\n",
    "# qconfig_mapping = get_default_qat_qconfig_mapping()\n",
    "# student_prepared = prepare_fx(student, qconfig_mapping, example_inputs=torch.randn(1,3,224,224).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FR-iTCqDcF-2"
   },
   "outputs": [],
   "source": [
    "# Set to evaluation mode and convert\n",
    "student_prepared.eval()\n",
    "student_quantized = convert(student_prepared, inplace=False)\n",
    "\n",
    "# For FX Graph Mode:\n",
    "# student_quantized = convert_fx(student_prepared)\n",
    "\n",
    "# Verify quantization\n",
    "print(student_quantized)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "gpuType": "V28",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
